# Crowdfunding-ETL
Week 8 Challenge

## Resources: 
- Software: SQL, PostgreSQL, pgAdmin, JupyterNotebook 

## Overview:

  - ETL pipeline was created to move raw data to a SQL database.
  - Extracted data from an external file by using Python and Pandas.
  - Used regular expressions to extract numbers and text.
  - Cleaned and transform data by using Python and Pandas.
  - Design a database and a table schema by using an entity relationship diagram (ERD).
  - Loaded data into a PostgreSQL database.
  - Performed data analysis by using SQL queries.
![Image 1](https://github.com/Sergg99/Crowdfunding-ETL/blob/3f7c61fffb05aeb52c06588b47f3c0654650b5f5/Module%208/Week%208%20Challenge/CorwdFuinding-ETL/Resources/Images/Initial%20data.jpg)

![Image 2](https://github.com/Sergg99/Crowdfunding-ETL/blob/1bb4ebba192fd4eaebd12889d4735196e06421b9/Module%208/Week%208%20Challenge/CorwdFuinding-ETL/Resources/Images/QUICK%20DBD%20with%20backers.jpg)

## Purpose:
The purpose of this weeks analysis was based on a crowd-funding plattaform performing a independent funding for independent project and/or ventures. All the data was accessible from a large Excel file onto Python and PostgresSQL database. Britta, a junior SQL developer will need our help to perform the analysis. 


## Challange:
![Image 3](https://github.com/Sergg99/Crowdfunding-ETL/blob/1bb4ebba192fd4eaebd12889d4735196e06421b9/Module%208/Week%208%20Challenge/CorwdFuinding-ETL/Resources/Images/backers.jpg) 

This weeks project was challenging since we had to organized the data into a pipeline after being extracted from a large Excel file into four separate CSV files. Luckily, using Quick DBD helped us cutting down time and effort by mapping the database. ETL was something new to me which implied on extensive research when pipelining the data into our desired data frames. 

